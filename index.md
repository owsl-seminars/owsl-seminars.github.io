<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
>
</script>
<script
  type="text/javascript"
  charset="utf-8"
  src="https://vincenttam.github.io/javascripts/MathJaxLocal.js"
>
</script>

# One World

The effects of CoViD-19 pervades through research communities across the globe,
causing cancelled conferences, post-poned research visits, and suspended
projects. Like [many others](#other-one-world-seminars), we have sought 
other opportunities for collaboration in spite of the current state of
affairs and have therefore organized this online seminar 
series in statistical learning.

# Format

We are going to use [zoom](https://zoom.us/). The seminar will be 1 hour
long, with 45 minutes allocated to the presentation itself and 15 minutes to
discussions afterwards. 

Here are some ground rules for these seminars:

- Please use your real name as a handle.
- Please mute your microphone whenever you are not speaking.
- If you wish to ask a question, use the **raise hand** button in the
  **participants** window.

# Zoom link

<https://lu-se.zoom.us/j/65067339175>

# Program

The seminar is held on a weekly basis on **fridays** and will run
at least until June 12. Each seminar starts at
[16:30 CEST](https://www.thetimezoneconverter.com/?t=16%3A30%20pm&tz=Warsaw&).

[Link to calendar event](https://lu-se.zoom.us/meeting/u5Etce6rrTIrHdGmDxIUKT33_HsILcrt6Tui/ics?icsToken=98tyKu-trj0tGdecsR6CR_MMAo_oKOnztlhcgqd6kTv9KhV4VlClCcpRG558AsyG)

## Upcoming talk

### Friday, June 5, 16:30 CEST

- **Speaker**: Damian Brzyski
- **Title**: The adaptive incorporation of multiple sources of information in 
  Brain Imaging via penalized optimization
- **Abstract**: The use of multiple sources of information in regression 
  modeling has recently received a lot of attention in the statistical and brain
  imaging literature. This talk introduces a novel, fully-automatic statistical
  procedure that addresses the problem of linear regression coefficients 
  estimation in the situation when the additional information about 
  connectivities between variables is given. Our method, "Adaptive Information 
  Merging Estimator for Regression" (AIMER) enables for the incorporation of 
  multiple sources of such information as well as for the division of one 
  source into pieces and determining their impact on the estimates. We 
  performed extensive simulations to visualize the desired adjusting 
  properties of our method and show its advantages over the existing 
  approaches. We also applied AIMER to analyze structural brain imaging data 
  and to reveal the association between cortical thickness and HIV-related 
  outcomes.

### Friday, June 12, 16:30 CEST

- **Speaker**: Aaron Molstad
- **Title**: Insights and algorithms for the multivariate square-root lasso
- **Abstract**: We study the multivariate square-root lasso, a method for 
  fitting the multivariate response (i.e. multi-task) linear regression 
  model with dependent errors. This estimator minimizes the nuclear norm of the 
  residual matrix plus a convex penalty. Unlike some existing methods for 
  multivariate response linear regression, which require explicit estimates of
  the error covariance matrix or its inverse, the multivariate square-root 
  lasso criterion implicitly adapts to dependent errors and is convex. To
  justify the use of this estimator, we establish an error bound which 
  illustrates that like the univariate square-root lasso, the multivariate
  square-root lasso is pivotal with respect to the unknown error covariance
  matrix. Based on our theory, we propose a simple tuning approach which 
  requires fitting the model for only a single value of the tuning parameter,
  e.g., does not require cross-validation. We propose two algorithms to compute
  the estimator: a prox-linear alternating direction method of multipliers 
  algorithm, and an accelerated first order algorithm which can be applied in
  certain cases. In both simulation studies and a genomic data application, we 
  show that the multivariate square-root lasso can outperform more 
  computationally intensive methods which estimate both the regression 
  coefficient matrix and error precision matrix.

## Previous talks

| Date   | Speaker           | Title                                                                        | Resources                                                                                                                       |
| :----- | :---------------- | :--------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------ |
| May 29 | Wojchiech Rejchel | Fast and robust procedures in high-dimensional variable selection            | [presentation](https://vimeo.com/424316618), [slides](slides/200529-rejchel.pdf), [paper](https://arxiv.org/abs/1905.05876)      |
| May 22 | Jaroslaw Harezlak | Brain Connectivity-Informed Adaptive Regularization for Generalized Outcomes | [presentation](https://vimeo.com/421641945), [slides](slides/200522-harezlak-brainimaging.pdf)                                  |
| May 22 | Jaroslaw Harezlak | Wearable Devices - Statistical Learning to the Rescue                        | [presentation](https://vimeo.com/421640615), [slides](slides/200522-harezlak-accelerometry.pdf)                                 |
| May 8  | Johan Larsson     | The strong screening rule for SLOPE                                          | [presentation](https://vimeo.com/416633997), [slides](slides/200508-johanlarsson.pdf), [paper](http://arxiv.org/abs/2005.03730) |
| May 8  | Patrick Tardivel  | Screening rules for the lasso                                                | [presentation](https://vimeo.com/416630058)                                                                                     |

# Recordings

Recordings of the talks on this seminar are hosted at
<https://vimeo.com/channels/statlearnseminar>.

# Organization

This seminar series is organized by 
[The Department of Mathematics, Wroc≈Çaw University](https://www.math.uni.wroc.pl) and 
[The Department of Statistics, Lund University](https://stat.lu.se).

# Other Online Seminars

- [One World Probability Seminar](https://www.wim.uni-mannheim.de/doering/one-world/)
- [One World Optimization Seminar](https://owos.univie.ac.at/)
- [One World ABC (Approximate Bayesian Computation) Seminar](https://warwick.ac.uk/fac/sci/statistics/news/upcoming-seminars/abcworldseminar)
- [One World Mathematics of INformation, Data, and Signals (MINDS) Seminar](https://sites.google.com/view/minds-seminar/home)
- [One World Stochastic Numerics and Inverse Problems (SNIP) Seminar](https://www.icms.org.uk/V_SNIPS.php)
- [One World PDE Seminar](https://people.bath.ac.uk/mw2319/owpde/)
- [One World Mathematical Game Theory Seminar](https://gametheorynetwork.com/one-world-game-theory-seminar/)
- [One World Seminar: Mathematical Methods for Arbitrary Data Sources](http://www.nonlocal-methods.eu/oneworld/)
- [One World Cognitive Psychologie Seminar](https://www.sowi.uni-mannheim.de/en/erdfelder/research/one-world-cps/)
- [International Seminar on Selective Inference](https://www.selectiveinferenceseminar.com)
- [Online Causal Inference Seminar](https://sites.google.com/view/ocis/home)

